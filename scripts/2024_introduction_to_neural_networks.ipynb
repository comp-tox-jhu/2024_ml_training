{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Introduction to Neural Networks\n",
        "subtitle: ''\n",
        "editor: visual\n",
        "author: Jason Laird\n",
        "date: 06/12/2024\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-location: left\n",
        "    theme:\n",
        "      - flatly\n",
        "    linkcolor: '#555580'\n",
        "---"
      ],
      "id": "f638b175"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Packages\n",
        "\n",
        "<https://www.kaggle.com/code/ryanholbrook/a-single-neuron>\n",
        "\n",
        "<https://www.geeksforgeeks.org/introduction-to-recurrent-neural-network/?ref=lbp>\n",
        "\n",
        "<https://www.kaggle.com/learn/computer-vision>\n",
        "\n",
        "\n",
        "\n",
        "## Load Data\n",
        "\n",
        "We split the dataset into training and test sets using $X_{train}$, $$X_{test}$$, $$Y_{train}$$, and $$Y_{test}$$. We then standardize our data to ensure each feature $X_i$​ has a mean of 0 and a standard deviation of 1:\n",
        "\n",
        "𝑋scaled=𝑋−𝜇𝜎Xscaled​=σX−μ​ where 𝜇μ is the mean and 𝜎σ is the standard deviation of the feature.\n"
      ],
      "id": "7fb9bd26"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"C:/Users/Jason/Documents/jhu/projects/2024_ml_training/results/brainspan_log.csv\")\n",
        "\n",
        "data = pd.read_csv(\"../results/brainspan_log.csv\")\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = data.drop(columns=['gender'])\n",
        "y = data['gender']\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the feature columns\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "id": "b700e80e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Build a Basic Neural Network with One Node**\n",
        "\n",
        "1.  **Initialization:** We create a Sequential model which will stack layers sequentially.\n",
        "\n",
        "2.  **Single Neuron Layer:**\n",
        "\n",
        "    -   **Dense Layer:** A fully connected layer with one neuron.\n",
        "\n",
        "    -   **Input Dimension:** input_dim=𝑛input_dim=n where 𝑛n is the number of input features.\n",
        "\n",
        "    -   **Activation Function:** Sigmoid function 𝜎(𝑧)=11+𝑒−𝑧σ(z)=1+e−z1​.\n",
        "\n",
        "3.  **Loss Function:**\n",
        "\n",
        "    -   **Binary Cross-Entropy:** For binary classification, the loss function is: 𝐿(𝑦,𝑦^)=−1𝑚∑𝑖=1𝑚\\[𝑦𝑖log⁡(𝑦𝑖)+(1−𝑦𝑖)log⁡(1−𝑦^𝑖)\\]L(y,y​)=−m1​∑i=1m​\\[yi​log(y^​i​)+(1−yi​)log(1−y^​i​)\\] where 𝑦y is the true label and 𝑦^y^​ is the predicted probability.\n",
        "\n",
        "4.  **Optimizer:** Adam optimizer adjusts weights using gradients.\n"
      ],
      "id": "dd5dcbff"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Initialize the neural network\n",
        "model = Sequential()\n",
        "\n",
        "# Add a single neuron\n",
        "model.add(Dense(1, input_dim=X_train.shape[1], activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))"
      ],
      "id": "3d517d6a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Build a More Complex Neural Network for Classification**\n",
        "\n",
        "1.  **Hidden Layers:**\n",
        "\n",
        "    -   **ReLU Activation:** ReLU(𝑧)=max⁡(0,𝑧)ReLU(z)=max(0,z). Introduces non-linearity and helps with vanishing gradient problem.\n",
        "\n",
        "    -   The hidden layers consist of 64, 32, and 16 neurons respectively.\n",
        "\n",
        "2.  **Output Layer:** Same as before with a sigmoid activation for binary classification.\n",
        "\n",
        "3.  **Training:** The model learns to minimize the loss function over epochs.\n"
      ],
      "id": "3b2b586c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize the neural network\n",
        "model = Sequential()\n",
        "\n",
        "# Add layers\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))"
      ],
      "id": "0e02cdeb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the Model\n",
        "\n",
        "1.  **Evaluation:** The model's performance is evaluated using the test set.\n",
        "\n",
        "2.  **Accuracy:** The fraction of correct predictions: Accuracy=Number of Correct PredictionsTotal Number of PredictionsAccuracy=Total Number of PredictionsNumber of Correct Predictions​\n"
      ],
      "id": "bf5cc197"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy*100:.2f}%')"
      ],
      "id": "4dd12ac3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Visualize the Training Process**\n",
        "\n",
        "1.  **Visualization:** Plotting accuracy and loss over epochs helps understand the model's learning process.\n",
        "\n",
        "2.  **Training vs. Validation:** Helps detect overfitting if the training accuracy improves but validation accuracy plateaus or decreases.\n"
      ],
      "id": "60d84de3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "7a3cca9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Make Predictions**\n",
        "\n",
        "1.  **Predictions:** The model outputs probabilities.\n",
        "\n",
        "2.  **Thresholding:** Convert probabilities to class labels (0 or 1) based on a threshold of 0.5.\n"
      ],
      "id": "f9effb0f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "predictions = (predictions > 0.5).astype(int)"
      ],
      "id": "b0fb7eda",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}